# Psycial - MBTI Classifier Configuration

[data]
# Path to training data
csv_path = "data/mbti_1.csv"
# Train/test split ratio (0.8 = 80% train, 20% test)
train_split = 0.8

[features]
# Maximum number of TF-IDF features
max_tfidf_features = 5000
# BERT model automatically provides 384 dimensions

# Psychological features from SEANCE, TAACO, TAALES frameworks
# Set to true to integrate psychological features (emotion, cohesion, lexical sophistication)
use_psychological_features = false
# Feature type: "simple" (9 features), "selected" (108 features), "full" (930 features)
# - simple: Top 9 emotion/power features (fast, ~0.1s overhead)
# - selected: 108 features via Pearson selection (recommended, ~30s overhead)
# - full: All 930 features (slow, may need more epochs)
psy_feature_type = "selected"

[model]
# Model type: "single" (16-way classification) or "multitask" (4 x 2-way classification)
# Multitask is more aligned with MBTI theory and often achieves better results
# Can be overridden via command-line: --multi-task or --single-task
#model_type = "multitask"
model_type = 'single'
# Network architecture (hidden layer sizes)
# 4-layer deep network optimized for MBTI classification
hidden_layers = [1024, 768, 512, 256]
# Learning rate for Adam optimizer
learning_rate = 0.001
# Dropout rate for regularization (0.0-1.0)
# Higher values = stronger regularization, less overfitting
# 0.3 is balanced - 0.6 was too aggressive and prevented learning
dropout_rate = 0.5
# Weight decay (L2 regularization) for Adam optimizer (0.0-0.1)
# Typical values: 0.0001-0.01. Higher values = stronger regularization
# Reduced from 0.01 to avoid over-regularization
weight_decay = 0.000

[training]
# Number of training epochs (for single-task model)
epochs = 30
# Batch size for training
batch_size = 64
# BERT batch processing size
bert_batch_size = 64

# Per-dimension epochs for multi-task model [E/I, S/N, T/F, J/P]
# Adjusted based on data distribution imbalance:
# - E/I: 40 epochs (77% vs 23%, moderate imbalance, needs learning)
# - S/N: 50 epochs (86% vs 14%, MOST imbalanced) ← needs most training
# - T/F: 40 epochs (54% vs 46%, most balanced but weakest dimension)
# - J/P: 40 epochs (60% vs 40%, moderate)
# Increased from previous low values to allow actual learning
#per_dimension_epochs = [40, 50, 40, 40]
per_dimension_epochs = [30, 30, 25, 30]

# Loss weights for each dimension [E/I, S/N, T/F, J/P]
# Higher weight = model focuses more on that dimension during training
# Strategy: boost weaker dimensions to improve overall accuracy
# - E/I: 1.0 (standard, already performs well at 76.9%)
# - S/N: 1.0 (standard, already performs best at 86.0%)
# - T/F: 1.5 (boosted, weakest dimension at 53.8% needs more focus) ← KEY
# - J/P: 1.2 (slightly boosted, moderate at 60.4%)
# Overall accuracy = E/I × S/N × T/F × J/P, so improving T/F has biggest impact
dimension_loss_weights = [1.2, 1.0, 1.0, 1.3]

[output]
# Directory to save trained models
model_dir = "models"
# Model file names (base names, suffix will be added automatically)
# Multi-task models: *_multitask.json, *_multitask.pt
# Single-task models: *_single.json, *_single.pt, class_mapping_single.json
tfidf_file = "tfidf_vectorizer.json"
mlp_file = "mlp_weights.pt"
class_mapping_file = "class_mapping.json"

# ===================================================================
# OPTIMIZATION RESULTS (Multi-Task Model)
# ===================================================================
# 
# BEST CONFIGURATION → Test Accuracy: 49.74%
# - Architecture: [1024, 768, 512, 256]
# - Per-dimension epochs: [30, 30, 25, 30]
# - Dimension weights: [1.2, 1.0, 1.0, 1.3]
# - Per-Dimension Accuracy: E/I=80.75%, S/N=90.03%, T/F=81.21%, J/P=75.16%
# 
# ===================================================================

# Experiment notes:
# - dropout_rate 0.5 with epochs 25: Good balance, test ~49%
# - dropout_rate 0.6 with epochs 20: Stronger regularization
# - dropout_rate 0.4 with epochs 40: Overfitting (train 99%, test 49%)
#
# With psychological features:
# - use_psychological_features = false, psy_feature_type = "selected"
#   Expected: 5000 (TF-IDF) + 384 (BERT) + 108 (Psy) = 5492 features
#   Target accuracy: 60-75% (vs 55-60% without psy features)
#   Training time: +30s for feature extraction and selection

