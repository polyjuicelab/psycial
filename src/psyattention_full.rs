mod psyattention;

use csv::ReaderBuilder;
use rand::seq::SliceRandom;
use rand::thread_rng;
use serde::Deserialize;
use std::collections::HashMap;
use std::error::Error;
use std::fs::File;
use std::time::Instant;

use psyattention::full_classifier::FullPsyAttentionClassifier;

#[derive(Debug, Deserialize, Clone)]
struct MbtiRecord {
    #[serde(rename = "type")]
    mbti_type: String,
    posts: String,
}

fn calculate_accuracy(predictions: &[String], actual: &[String]) -> f64 {
    let correct = predictions
        .iter()
        .zip(actual.iter())
        .filter(|(pred, act)| pred == act)
        .count();
    correct as f64 / predictions.len() as f64
}

fn main() -> Result<(), Box<dyn Error>> {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  PsyAttention - FULL Implementation (930 Features)            â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    
    println!("Paper: 'PsyAttention: Psychological Attention Model'");
    println!("Authors: Baohua Zhang et al., Beijing Institute of Technology");
    println!("Published: arXiv:2312.00293v1, December 2023");
    println!("Target Accuracy: 86.30% (SOTA on MBTI Kaggle dataset)\n");
    
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    // Load data
    println!("ğŸ“š Loading MBTI Kaggle dataset...");
    let start_load = Instant::now();
    
    let file = File::open("data/mbti_1.csv")?;
    let mut rdr = ReaderBuilder::new().has_headers(true).from_reader(file);

    let mut records: Vec<MbtiRecord> = Vec::new();
    for result in rdr.deserialize() {
        let record: MbtiRecord = result?;
        records.push(record);
    }

    println!("   âœ“ Loaded {} records in {:.2}s\n", records.len(), start_load.elapsed().as_secs_f64());

    // Shuffle data
    let mut rng = thread_rng();
    records.shuffle(&mut rng);

    // Split train/test (80/20)
    let split_idx = (records.len() as f64 * 0.8) as usize;
    let train_records = &records[..split_idx];
    let test_records = &records[split_idx..];

    println!("ğŸ“Š Dataset Split:");
    println!("   Training set: {} samples (80%)", train_records.len());
    println!("   Test set:     {} samples (20%)", test_records.len());
    
    // Show class distribution
    let mut class_counts: HashMap<String, usize> = HashMap::new();
    for record in train_records {
        *class_counts.entry(record.mbti_type.clone()).or_insert(0) += 1;
    }
    let mut sorted_classes: Vec<_> = class_counts.iter().collect();
    sorted_classes.sort_by(|a, b| b.1.cmp(a.1));
    
    println!("\nğŸ“ˆ Class Distribution (Top 5):");
    for (class, count) in sorted_classes.iter().take(5) {
        let pct = (**count as f64 / train_records.len() as f64) * 100.0;
        let bar = "â–ˆ".repeat((pct / 2.0) as usize);
        println!("   {}: {:>4} ({:>5.1}%) {}", class, count, pct, bar);
    }
    println!();

    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    // Create classifier with feature selection
    println!("ğŸ”§ Configuration:");
    println!("   Full features: 930 (SEANCE=271, TAACO=168, TAALES=491)");
    println!("   Target features after Pearson selection: 108");
    println!("   Correlation threshold: 0.85");
    println!("   Attention-based encoding: Enabled\n");

    let start_train = Instant::now();
    
    let mut classifier = FullPsyAttentionClassifier::new(108);
    
    let train_texts: Vec<String> = train_records.iter().map(|r| r.posts.clone()).collect();
    let train_labels: Vec<String> = train_records.iter().map(|r| r.mbti_type.clone()).collect();
    
    println!("ğŸ“ Training Full PsyAttention Classifier...\n");
    classifier.train(&train_texts, &train_labels);
    
    let train_time = start_train.elapsed().as_secs_f64();
    println!("\n   âœ“ Training completed in {:.2}s", train_time);

    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    // Evaluate on training set
    println!("ğŸ“Š Evaluating on Training Set...");
    let eval_start = Instant::now();
    
    let train_predictions: Vec<String> = train_texts
        .iter()
        .map(|text| classifier.predict(text))
        .collect();
    let train_accuracy = calculate_accuracy(&train_predictions, &train_labels);
    
    println!("   Training Accuracy: {:.2}%", train_accuracy * 100.0);
    println!("   Evaluation time: {:.2}s", eval_start.elapsed().as_secs_f64());

    // Evaluate on test set
    println!("\nğŸ“Š Evaluating on Test Set...");
    let test_start = Instant::now();
    
    let test_texts: Vec<String> = test_records.iter().map(|r| r.posts.clone()).collect();
    let test_labels: Vec<String> = test_records.iter().map(|r| r.mbti_type.clone()).collect();
    
    let test_predictions: Vec<String> = test_texts
        .iter()
        .map(|text| classifier.predict(text))
        .collect();
    let test_accuracy = calculate_accuracy(&test_predictions, &test_labels);
    
    println!("   Test Accuracy: {:.2}%", test_accuracy * 100.0);
    println!("   Evaluation time: {:.2}s", test_start.elapsed().as_secs_f64());

    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    // Detailed sample analysis
    println!("ğŸ” Sample Predictions with Feature Analysis:\n");
    
    for i in 0..3.min(test_records.len()) {
        println!("â”€â”€â”€ Sample {} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€", i + 1);
        println!("Text preview: {}...", 
                 &test_records[i].posts.chars().take(80).collect::<String>());
        println!();
        println!("Actual:    {}", test_records[i].mbti_type);
        println!("Predicted: {}", test_predictions[i]);
        println!("Match:     {}", if test_predictions[i] == test_records[i].mbti_type {
            "âœ“ CORRECT"
        } else {
            "âœ— INCORRECT"
        });
        
        // Feature analysis
        let analysis = classifier.analyze_features(&test_records[i].posts);
        println!("\nFeature Category Analysis:");
        println!("  SEANCE  (Emotion):      {:.4}", analysis.get("seance_mean").unwrap_or(&0.0));
        println!("  TAACO   (Cohesion):     {:.4}", analysis.get("taaco_mean").unwrap_or(&0.0));
        println!("  TAALES  (Sophistication): {:.4}", analysis.get("taales_mean").unwrap_or(&0.0));
        
        // Probability distribution
        let proba = classifier.predict_proba(&test_records[i].posts);
        let mut proba_vec: Vec<_> = proba.iter().collect();
        proba_vec.sort_by(|a, b| b.1.partial_cmp(a.1).unwrap());
        
        println!("\nTop 3 Predictions:");
        for (rank, (class, prob)) in proba_vec.iter().take(3).enumerate() {
            println!("  {}. {}: {:.2}%", rank + 1, class, **prob * 100.0);
        }
        println!();
    }

    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    // Final comparison
    println!("ğŸ“ˆ Performance Summary:\n");
    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚ Implementation                             â”‚ Accuracy â”‚");
    println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
    println!("â”‚ Random Guessing (baseline)                 â”‚   6.25%  â”‚");
    println!("â”‚ TF-IDF + Naive Bayes (baseline)            â”‚  21.73%  â”‚");
    println!("â”‚ PsyAttention Simple (9 features)           â”‚  21.21%  â”‚");
    println!("â”‚ PsyAttention Full (930â†’108 features)       â”‚ {:>6.2}%  â”‚", test_accuracy * 100.0);
    println!("â”‚ Paper Target (full implementation + BERT) â”‚  86.30%  â”‚");
    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");
    
    println!("\nğŸ“ Analysis:");
    let improvement_over_random = test_accuracy / 0.0625;
    println!("   â€¢ {:.1}x better than random guessing", improvement_over_random);
    println!("   â€¢ {:.1}% of paper target achieved", (test_accuracy / 0.863) * 100.0);
    
    println!("\nğŸ’¡ To reach paper performance (86.30%), still needed:");
    println!("   âœ— BERT fine-tuning and integration");
    println!("   âœ— 8-layer Transformer encoder (currently simplified)");
    println!("   âœ— Two-stage training strategy");
    println!("   âœ— GPU acceleration");
    println!("   âœ— Dynamic fusion layer");
    
    println!("\nâœ“ Successfully implemented:");
    println!("   âœ“ 930 psychological features (SEANCE + TAACO + TAALES)");
    println!("   âœ“ Pearson correlation feature selection");
    println!("   âœ“ Attention-based feature encoding");
    println!("   âœ“ Class-balanced training");
    
    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    println!("ğŸ‰ Full PsyAttention implementation complete!");
    println!("\n");

    Ok(())
}

